{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split-Apply-Combine More\n",
    "\n",
    "### Objectives\n",
    "After this lesson you should be able to...\n",
    "+ Create custom aggregation functions to pass to groupby objects\n",
    "+ Know how to use the primary groupby methods **`agg`**, **`filter`**, **`transform`** and **`apply`**\n",
    "+ Know the differences between **`agg`**, **`filter`**, **`transform`** and **`apply`**\n",
    "\n",
    "### Prepare for this lesson by\n",
    "+ Reading the rest of the [split apply combine](http://pandas.pydata.org/pandas-docs/stable/groupby.html#transformation) documentation from Transformation until the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom aggregate functions\n",
    "Pandas groupby objects come with a few dozen aggregate functions that can be applied to the groups. It is also possible to define your own customized aggregate function. These customized functions must return a single value.\n",
    "\n",
    "Let's suppose you would like to know the difference between the max and min value of a column. Pandas does not have an aggregate function built to do this. You would have to define one yourself. \n",
    "\n",
    "Each customized aggregate function is defined as normal with the **`def`** keyword. Each function will accept one argument and that is the aggregating column. It will be passed as a **`Series`**. This means that all Series methods will work on the passed argument.\n",
    "\n",
    "The **`min_max`** function below takes one argument, **`s`** which is a Series object. It returns the difference between the max and min values of that Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define custom function\n",
    "# s is a Series\n",
    "\n",
    "def min_max(s):\n",
    "    return s.max() - s.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in college DF\n",
    "college = pd.read_csv('data/college.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>min_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AK</th>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>12865.0</td>\n",
       "      <td>12756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AL</th>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29851.0</td>\n",
       "      <td>29839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3033.0</td>\n",
       "      <td>3020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AR</th>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21405.0</td>\n",
       "      <td>21387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4485.0</td>\n",
       "      <td>4465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AS</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AZ</th>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>151558.0</td>\n",
       "      <td>151557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4102.0</td>\n",
       "      <td>4077.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CA</th>\n",
       "      <th>0</th>\n",
       "      <td>609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44744.0</td>\n",
       "      <td>44744.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6745.0</td>\n",
       "      <td>6737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <th>0</th>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25873.0</td>\n",
       "      <td>25873.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 size     min       max   min_max\n",
       "STABBR RELAFFIL                                  \n",
       "AK     0            7   109.0   12865.0   12756.0\n",
       "       1            3    27.0     275.0     248.0\n",
       "AL     0           72    12.0   29851.0   29839.0\n",
       "       1           24    13.0    3033.0    3020.0\n",
       "AR     0           68    18.0   21405.0   21387.0\n",
       "       1           18    20.0    4485.0    4465.0\n",
       "AS     0            1  1276.0    1276.0       0.0\n",
       "AZ     0          124     1.0  151558.0  151557.0\n",
       "       1            9    25.0    4102.0    4077.0\n",
       "CA     0          609     0.0   44744.0   44744.0\n",
       "       1          164     8.0    6745.0    6737.0\n",
       "CO     0          118     0.0   25873.0   25873.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use new min_max function\n",
    "college.groupby(['STABBR', 'RELAFFIL'])['UGDS'].agg(['size', 'min', 'max', min_max]).head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out groups\n",
    "\n",
    "**`groupby`** objects come with a **`filter`** method that...\n",
    "1. Scans each group independently\n",
    "2. Applies a function to each group and returns a boolean value\n",
    "3. Keeps the group or drops each group based on the boolean value returned from the function\n",
    "4. The end result is the original DataFrame (same number of columns) with certain groups filtered out\n",
    "\n",
    "The **`filter`** method accepts a function that returns either True or False for each group. This result is used to filter the original DataFrame.\n",
    "\n",
    "The function that **`filter`** accepts will be a **custom** function that is **`implicitly`** passed a DataFrame of each group.\n",
    "\n",
    "Anything can happen inside the body of the function passed to **`filter`** but it must return **`True`** or **`False`**. This boolean value determines whether the group is included or is dropped from the final resulting DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find states with more than 300,000 undergraduate students\n",
    "To help provide some context, we will use the filter method to find states that have at least 300,000 undergraduate students. The **`filter`** is passed a function that will sum all the undergraduate students for each state. It will take this sum and compare it against the number 300,000 and return **`True`** or **`False`**. Only states that have more than 300,000 students will remain.\n",
    "\n",
    "None of the values in the DataFrame are mutated. Only rows are dropped with **`filter`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function that accepts a dataframe of the current group\n",
    "# it must return a boolean\n",
    "\n",
    "def filter_ugds(df):\n",
    "    return df['UGDS'].sum() > 300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use filter\n",
    "college_filtered = college.groupby('STABBR').filter(filter_ugds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7535, 27)\n",
      "(4619, 27)\n"
     ]
    }
   ],
   "source": [
    "# see the difference in size\n",
    "print(college.shape)\n",
    "print(college_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass additional parameters to the filtering function\n",
    "At first glance the **`filter`** method from above appears to only allow the passed function to contain a single argument. This is not the case. You can pass any number of arguments to the function inside of **`filter`**.\n",
    "\n",
    "Let's take a look at the **`filter`** docstrings for a moment. Since **`filter`** is a chained method the docstring intelligence tricks (shift + tab + tab, etc...) are not available to us. We can use the help function to output the docstrings into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method filter in module pandas.core.groupby:\n",
      "\n",
      "filter(func, dropna=True, *args, **kwargs) method of pandas.core.groupby.DataFrameGroupBy instance\n",
      "    Return a copy of a DataFrame excluding elements from groups that\n",
      "    do not satisfy the boolean criterion specified by func.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    f : function\n",
      "        Function to apply to each subframe. Should return True or False.\n",
      "    dropna : Drop groups that do not pass the filter. True by default;\n",
      "        if False, groups that evaluate False are filled with NaNs.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Each subframe is endowed the attribute 'name' in case you need to know\n",
      "    which group you are working on.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> grouped = df.groupby(lambda x: mapping[x])\n",
      "    >>> grouped.filter(lambda x: x['A'].sum() + x['B'].sum() > 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(college.groupby('STABBR').filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*args and \\*\\*kwargs\n",
    "Notice in the method header the two additional parameters, \\*args and \\*\\*kwargs that not formally mentioned in the parameter list. These two additional parameters will not be explained here but there is a great [stackoverflow post](http://stackoverflow.com/questions/3394835/args-and-kwargs) where you can learn all about them.\n",
    "\n",
    "### What it means for `filter`\n",
    "You can pass additional arguments to the function that **`filter`** accepts. This becomes useful when we want to customize the filter based on some parameter.\n",
    "\n",
    "Let's rebuild the filtering function to accept a **`num_students`** argument that allows more flexibility when determining which states to filter out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define new function with additional arguments\n",
    "def filter_ugds_param(df, num_students):\n",
    "    return df['UGDS'].sum() > num_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "college_filtered2 = college.groupby('STABBR').filter(filter_ugds_param, num_students=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3319, 27)\n",
      "(4619, 27)\n",
      "(7535, 27)\n"
     ]
    }
   ],
   "source": [
    "print(college_filtered2.shape)\n",
    "print(college_filtered.shape)\n",
    "print(college.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby with Series\n",
    "\n",
    "Pandas Series also have a **`groupby`** method. You might be thinking how it's possible to group and aggregate a single column of data. It becomes possible when you consider the **index** and the many levels that an index can have. Multi-level indexes will be discussed in another notebook.\n",
    "\n",
    "To make the index meaningful set it to be one of the columns of the DataFrame with the **`set_index`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>DISTANCEONLY</th>\n",
       "      <th>UGDS</th>\n",
       "      <th>UGDS_WHITE</th>\n",
       "      <th>UGDS_BLACK</th>\n",
       "      <th>UGDS_HISP</th>\n",
       "      <th>UGDS_ASIAN</th>\n",
       "      <th>UGDS_AIAN</th>\n",
       "      <th>UGDS_NHPI</th>\n",
       "      <th>UGDS_2MOR</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>CURROPER</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4206.0</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.9353</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>30300</td>\n",
       "      <td>33888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11383.0</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.2607</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>39700</td>\n",
       "      <td>21941.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Amridge University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.4192</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.4536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>40100</td>\n",
       "      <td>23370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>0.6988</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.2146</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3072</td>\n",
       "      <td>0.4596</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>45500</td>\n",
       "      <td>24097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4811.0</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.9208</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7347</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>26600</td>\n",
       "      <td>33118.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     INSTNM        CITY  HBCU  MENONLY  \\\n",
       "STABBR                                                                   \n",
       "AL                 Alabama A & M University      Normal   1.0      0.0   \n",
       "AL      University of Alabama at Birmingham  Birmingham   0.0      0.0   \n",
       "AL                       Amridge University  Montgomery   0.0      0.0   \n",
       "AL      University of Alabama in Huntsville  Huntsville   0.0      0.0   \n",
       "AL                 Alabama State University  Montgomery   1.0      0.0   \n",
       "\n",
       "        WOMENONLY  RELAFFIL  SATVRMID  SATMTMID  DISTANCEONLY     UGDS  \\\n",
       "STABBR                                                                   \n",
       "AL            0.0         0     424.0     420.0           0.0   4206.0   \n",
       "AL            0.0         0     570.0     565.0           0.0  11383.0   \n",
       "AL            0.0         1       NaN       NaN           1.0    291.0   \n",
       "AL            0.0         0     595.0     590.0           0.0   5451.0   \n",
       "AL            0.0         0     425.0     430.0           0.0   4811.0   \n",
       "\n",
       "        UGDS_WHITE  UGDS_BLACK  UGDS_HISP  UGDS_ASIAN  UGDS_AIAN  UGDS_NHPI  \\\n",
       "STABBR                                                                        \n",
       "AL          0.0333      0.9353     0.0055      0.0019     0.0024     0.0019   \n",
       "AL          0.5922      0.2600     0.0283      0.0518     0.0022     0.0007   \n",
       "AL          0.2990      0.4192     0.0069      0.0034     0.0000     0.0000   \n",
       "AL          0.6988      0.1255     0.0382      0.0376     0.0143     0.0002   \n",
       "AL          0.0158      0.9208     0.0121      0.0019     0.0010     0.0006   \n",
       "\n",
       "        UGDS_2MOR  UGDS_NRA  UGDS_UNKN  PPTUG_EF  CURROPER  PCTPELL  PCTFLOAN  \\\n",
       "STABBR                                                                          \n",
       "AL         0.0000    0.0059     0.0138    0.0656         1   0.7356    0.8284   \n",
       "AL         0.0368    0.0179     0.0100    0.2607         1   0.3460    0.5214   \n",
       "AL         0.0000    0.0000     0.2715    0.4536         1   0.6801    0.7795   \n",
       "AL         0.0172    0.0332     0.0350    0.2146         1   0.3072    0.4596   \n",
       "AL         0.0098    0.0243     0.0137    0.0892         1   0.7347    0.7554   \n",
       "\n",
       "        UG25ABV MD_EARN_WNE_P10 GRAD_DEBT_MDN_SUPP  \n",
       "STABBR                                              \n",
       "AL       0.1049           30300              33888  \n",
       "AL       0.2422           39700            21941.5  \n",
       "AL       0.8540           40100              23370  \n",
       "AL       0.2640           45500              24097  \n",
       "AL       0.1270           26600            33118.5  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new dataframe with a more interesting index\n",
    "college_state_index = college.set_index('STABBR')\n",
    "\n",
    "college_state_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by the Index\n",
    "\n",
    "The **`groupby`** method uses the **`level`** argument to contain the name (or integer location) of the index you would like to form groups with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR\n",
       "AL     4206.0\n",
       "AL    11383.0\n",
       "AL      291.0\n",
       "AL     5451.0\n",
       "AL     4811.0\n",
       "Name: UGDS, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a Series by selecting one column\n",
    "s = college_state_index['UGDS']\n",
    "\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STABBR'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the name can be retrieved with the name attribute of the index\n",
    "s.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR\n",
       "AK    2493.200000\n",
       "AL    2789.865169\n",
       "AR    1644.146341\n",
       "AS    1276.000000\n",
       "AZ    4130.468254\n",
       "CA    3518.308397\n",
       "CO    2324.880342\n",
       "CT    1873.550562\n",
       "DC    2645.277778\n",
       "DE    2491.052632\n",
       "Name: UGDS, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupby as normal but with the level argument\n",
    "# get the mean of the undergrad student population\n",
    "\n",
    "s.groupby(level='STABBR').mean().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR\n",
       "AK    2493.200000\n",
       "AL    2789.865169\n",
       "AR    1644.146341\n",
       "AS    1276.000000\n",
       "AZ    4130.468254\n",
       "CA    3518.308397\n",
       "CO    2324.880342\n",
       "CT    1873.550562\n",
       "DC    2645.277778\n",
       "DE    2491.052632\n",
       "Name: UGDS, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should give the same result as dataframe\n",
    "college.groupby('STABBR')['UGDS'].mean().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tranforming and not aggregating groups\n",
    "\n",
    "The most common operation to apply to a group is some kind of aggregation. Getting a single number summary of a group is usually of primary concern. There are however instances where the entire group would like to be transformed with every row kept. The **`transform`** groupby method will apply a (usually) custom function to each column of each group returning data that is the same length as the group. \n",
    "\n",
    "One of the most common operations is to standardize data - that is transform a numerical group so that its mean is 0 and standard deviation is 1. This is [done in the documentation](http://pandas.pydata.org/pandas-docs/stable/groupby.html#transformation). \n",
    "\n",
    "# Case Study: Tracking Weight Loss per Month\n",
    "There are two friends interested in tracking their weight over the course of several months. To provide motivation they decide to wager some money each month. The friend who loses the highest percentage of body weight each month wins that month. Each month is independent from the others so the weight loss percentage resets at the start of the month.\n",
    "\n",
    "Below is the data that was collected over the course of the bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name Month    Week  Weight\n",
       "0   Bob   Jan  Week 1     290\n",
       "1   Amy   Jan  Week 1     196\n",
       "2   Bob   Jan  Week 2     292\n",
       "3   Amy   Jan  Week 2     189\n",
       "4   Bob   Jan  Week 3     287\n",
       "5   Amy   Jan  Week 3     183\n",
       "6   Bob   Jan  Week 4     287\n",
       "7   Amy   Jan  Week 4     177\n",
       "8   Bob   Feb  Week 1     282\n",
       "9   Amy   Feb  Week 1     177\n",
       "10  Bob   Feb  Week 2     276\n",
       "11  Amy   Feb  Week 2     171\n",
       "12  Bob   Feb  Week 3     276\n",
       "13  Amy   Feb  Week 3     166\n",
       "14  Bob   Feb  Week 4     267\n",
       "15  Amy   Feb  Week 4     166\n",
       "16  Bob   Mar  Week 1     269\n",
       "17  Amy   Mar  Week 1     166\n",
       "18  Bob   Mar  Week 2     265\n",
       "19  Amy   Mar  Week 2     165\n",
       "20  Bob   Mar  Week 3     260\n",
       "21  Amy   Mar  Week 3     166\n",
       "22  Bob   Mar  Week 4     252\n",
       "23  Amy   Mar  Week 4     164\n",
       "24  Bob   Apr  Week 1     244\n",
       "25  Amy   Apr  Week 1     165\n",
       "26  Bob   Apr  Week 2     244\n",
       "27  Amy   Apr  Week 2     162\n",
       "28  Bob   Apr  Week 3     235\n",
       "29  Amy   Apr  Week 3     157\n",
       "30  Bob   Apr  Week 4     228\n",
       "31  Amy   Apr  Week 4     152"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create fake data\n",
    "\n",
    "all_weight = np.zeros(32)\n",
    "all_weight[::2] = 300 * np.cumprod(np.random.rand(16) * .05 + .96)\n",
    "all_weight[1::2] = 200 * np.cumprod(np.random.rand(16) * .05 + .96)\n",
    "all_weight = np.round(all_weight, 0).astype(int)\n",
    "\n",
    "\n",
    "df_weight = pd.DataFrame({'Name':['Bob', 'Amy'] * 16, \n",
    "                          'Month': ('Jan ' * 8 + ' Feb' * 8 + ' Mar' * 8 + ' Apr' * 8).split(),\n",
    "                          'Week' : (['Week 1'] * 2 + ['Week 2'] * 2 + ['Week 3'] * 2 + ['Week 4'] * 2) * 4,\n",
    "                          'Weight':all_weight},\n",
    "                        columns=['Name', 'Month', 'Week', 'Weight'])\n",
    "\n",
    "df_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n",
    "A new bet is begun at the start of each month and the winner for each month is declared by percentage weight loss achieved from week 1 to week 4. Percentage weight loss resets to zero at the beginning of each month.\n",
    "\n",
    "We need to find a way to track the percentage weight loss within each month for each person. Since each week will have a weight loss percentage, no aggregation is performed and instead a new value is needed for each row. This situation calls for **`transform`**.\n",
    "\n",
    "The default behavior of transform is to apply the same function (given as an argument) to each non-grouped column of the DataFrame. Since columns are Series, it is a Series that is passed to the transformation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a custom function that takes a Series and find the percentage loss from the first week\n",
    "# is passed a Series\n",
    "\n",
    "def find_perc_loss(s):\n",
    "    return (s - s.iloc[0]) / s.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weight</th>\n",
       "      <th>percent_month_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>290</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>196</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>292</td>\n",
       "      <td>0.006897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>189</td>\n",
       "      <td>-0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>287</td>\n",
       "      <td>-0.010345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>183</td>\n",
       "      <td>-0.066327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>287</td>\n",
       "      <td>-0.010345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.096939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>282</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>177</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>276</td>\n",
       "      <td>-0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>171</td>\n",
       "      <td>-0.033898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>276</td>\n",
       "      <td>-0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>166</td>\n",
       "      <td>-0.062147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>267</td>\n",
       "      <td>-0.053191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>166</td>\n",
       "      <td>-0.062147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name Month    Week  Weight  percent_month_loss\n",
       "0   Bob   Jan  Week 1     290            0.000000\n",
       "1   Amy   Jan  Week 1     196            0.000000\n",
       "2   Bob   Jan  Week 2     292            0.006897\n",
       "3   Amy   Jan  Week 2     189           -0.035714\n",
       "4   Bob   Jan  Week 3     287           -0.010345\n",
       "5   Amy   Jan  Week 3     183           -0.066327\n",
       "6   Bob   Jan  Week 4     287           -0.010345\n",
       "7   Amy   Jan  Week 4     177           -0.096939\n",
       "8   Bob   Feb  Week 1     282            0.000000\n",
       "9   Amy   Feb  Week 1     177            0.000000\n",
       "10  Bob   Feb  Week 2     276           -0.021277\n",
       "11  Amy   Feb  Week 2     171           -0.033898\n",
       "12  Bob   Feb  Week 3     276           -0.021277\n",
       "13  Amy   Feb  Week 3     166           -0.062147\n",
       "14  Bob   Feb  Week 4     267           -0.053191\n",
       "15  Amy   Feb  Week 4     166           -0.062147"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by name and month\n",
    "# apply transformation\n",
    "# and only transform weight column\n",
    "df_weight['percent_month_loss'] = df_weight.groupby(['Name', 'Month'])['Weight'].transform(find_perc_loss) \n",
    "\n",
    "# view first two months. Notice that percent loss resets to 0\n",
    "df_weight.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weight</th>\n",
       "      <th>percent_month_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>165</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>162</td>\n",
       "      <td>-0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>157</td>\n",
       "      <td>-0.048485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>152</td>\n",
       "      <td>-0.078788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>177</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>171</td>\n",
       "      <td>-0.033898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>166</td>\n",
       "      <td>-0.062147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>166</td>\n",
       "      <td>-0.062147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>196</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>189</td>\n",
       "      <td>-0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>183</td>\n",
       "      <td>-0.066327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.096939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>166</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>165</td>\n",
       "      <td>-0.006024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>166</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>164</td>\n",
       "      <td>-0.012048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>244</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>244</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>235</td>\n",
       "      <td>-0.036885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>228</td>\n",
       "      <td>-0.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>282</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>276</td>\n",
       "      <td>-0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>276</td>\n",
       "      <td>-0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>267</td>\n",
       "      <td>-0.053191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>290</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>292</td>\n",
       "      <td>0.006897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>287</td>\n",
       "      <td>-0.010345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>287</td>\n",
       "      <td>-0.010345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>269</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>265</td>\n",
       "      <td>-0.014870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>260</td>\n",
       "      <td>-0.033457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>252</td>\n",
       "      <td>-0.063197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name Month    Week  Weight  percent_month_loss\n",
       "25  Amy   Apr  Week 1     165            0.000000\n",
       "27  Amy   Apr  Week 2     162           -0.018182\n",
       "29  Amy   Apr  Week 3     157           -0.048485\n",
       "31  Amy   Apr  Week 4     152           -0.078788\n",
       "9   Amy   Feb  Week 1     177            0.000000\n",
       "11  Amy   Feb  Week 2     171           -0.033898\n",
       "13  Amy   Feb  Week 3     166           -0.062147\n",
       "15  Amy   Feb  Week 4     166           -0.062147\n",
       "1   Amy   Jan  Week 1     196            0.000000\n",
       "3   Amy   Jan  Week 2     189           -0.035714\n",
       "5   Amy   Jan  Week 3     183           -0.066327\n",
       "7   Amy   Jan  Week 4     177           -0.096939\n",
       "17  Amy   Mar  Week 1     166            0.000000\n",
       "19  Amy   Mar  Week 2     165           -0.006024\n",
       "21  Amy   Mar  Week 3     166            0.000000\n",
       "23  Amy   Mar  Week 4     164           -0.012048\n",
       "24  Bob   Apr  Week 1     244            0.000000\n",
       "26  Bob   Apr  Week 2     244            0.000000\n",
       "28  Bob   Apr  Week 3     235           -0.036885\n",
       "30  Bob   Apr  Week 4     228           -0.065574\n",
       "8   Bob   Feb  Week 1     282            0.000000\n",
       "10  Bob   Feb  Week 2     276           -0.021277\n",
       "12  Bob   Feb  Week 3     276           -0.021277\n",
       "14  Bob   Feb  Week 4     267           -0.053191\n",
       "0   Bob   Jan  Week 1     290            0.000000\n",
       "2   Bob   Jan  Week 2     292            0.006897\n",
       "4   Bob   Jan  Week 3     287           -0.010345\n",
       "6   Bob   Jan  Week 4     287           -0.010345\n",
       "16  Bob   Mar  Week 1     269            0.000000\n",
       "18  Bob   Mar  Week 2     265           -0.014870\n",
       "20  Bob   Mar  Week 3     260           -0.033457\n",
       "22  Bob   Mar  Week 4     252           -0.063197"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it might be easier to read if sorted.\n",
    "# note that Month is not sorted lexicographically and not by calendar\n",
    "df_weight_final = df_weight.sort_values(['Name', 'Month', 'Week'])\n",
    "\n",
    "df_weight_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a winner\n",
    "\n",
    "It's possible to manually find a winner of each month by comparing each person's week 4. For instance, Amy lost 7.9% of her body weight in April compared to Bob's 6.6% and won that month.\n",
    "\n",
    "This is very tedious and since we have Pandas would be ridiculous to do by hand. We need to reshape the data in such a manner that each person's week 4 is easily comparable. There are many ways to reshape data. **`pivot`** and **`pivot_table`** DataFrame methods allow you to convert **long** formatted data into **wide** formatted data. This converts column values into column names. More will be said on this later.\n",
    "\n",
    "First the above DataFrame will be filtered for only week 4 and then pivoted to make the comparison easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weight</th>\n",
       "      <th>percent_month_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>152</td>\n",
       "      <td>-0.078788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>166</td>\n",
       "      <td>-0.062147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.096939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>164</td>\n",
       "      <td>-0.012048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>228</td>\n",
       "      <td>-0.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>267</td>\n",
       "      <td>-0.053191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>287</td>\n",
       "      <td>-0.010345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>252</td>\n",
       "      <td>-0.063197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name Month    Week  Weight  percent_month_loss\n",
       "31  Amy   Apr  Week 4     152           -0.078788\n",
       "15  Amy   Feb  Week 4     166           -0.062147\n",
       "7   Amy   Jan  Week 4     177           -0.096939\n",
       "23  Amy   Mar  Week 4     164           -0.012048\n",
       "30  Bob   Apr  Week 4     228           -0.065574\n",
       "14  Bob   Feb  Week 4     267           -0.053191\n",
       "6   Bob   Jan  Week 4     287           -0.010345\n",
       "22  Bob   Mar  Week 4     252           -0.063197"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weight_week4 = df_weight_final[df_weight_final['Week'] == 'Week 4']\n",
    "\n",
    "df_weight_week4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Name</th>\n",
       "      <th>Amy</th>\n",
       "      <th>Bob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apr</th>\n",
       "      <td>-0.078788</td>\n",
       "      <td>-0.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb</th>\n",
       "      <td>-0.062147</td>\n",
       "      <td>-0.053191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jan</th>\n",
       "      <td>-0.096939</td>\n",
       "      <td>-0.010345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar</th>\n",
       "      <td>-0.012048</td>\n",
       "      <td>-0.063197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Name        Amy       Bob\n",
       "Month                    \n",
       "Apr   -0.078788 -0.065574\n",
       "Feb   -0.062147 -0.053191\n",
       "Jan   -0.096939 -0.010345\n",
       "Mar   -0.012048 -0.063197"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use pivot_table to move the Name column\n",
    "df_weight_winner = df_weight_week4.pivot_table(index='Month', columns='Name', values='percent_month_loss')\n",
    "\n",
    "df_weight_winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column for winner with np.where\n",
    "\n",
    "Now that the winner is much more easily seen with the new reshaped data, a final step of creating a column with the winner's name can be made with the numpy **`where`** function. **`np.where`** works by an array of boolean values and returns an array consisting of the second argument wherever the array is True and the third argument False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No', 'No', 'Yes', 'No', 'Yes'], \n",
       "      dtype='<U3')"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a trivial example\n",
    "# Return 'Yes' when True and 'No' when False\n",
    "\n",
    "np.where([True, False, False, True, False, True], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Name</th>\n",
       "      <th>Amy</th>\n",
       "      <th>Bob</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apr</th>\n",
       "      <td>-0.078788</td>\n",
       "      <td>-0.065574</td>\n",
       "      <td>Amy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb</th>\n",
       "      <td>-0.062147</td>\n",
       "      <td>-0.053191</td>\n",
       "      <td>Amy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jan</th>\n",
       "      <td>-0.096939</td>\n",
       "      <td>-0.010345</td>\n",
       "      <td>Amy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar</th>\n",
       "      <td>-0.012048</td>\n",
       "      <td>-0.063197</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Name        Amy       Bob Winner\n",
       "Month                           \n",
       "Apr   -0.078788 -0.065574    Amy\n",
       "Feb   -0.062147 -0.053191    Amy\n",
       "Jan   -0.096939 -0.010345    Amy\n",
       "Mar   -0.012048 -0.063197    Bob"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the winner Amy when her weight loss is more than Bob's and vice versa using np.where\n",
    "df_weight_winner['Winner'] = np.where(df_weight_winner['Amy'] < df_weight_winner['Bob'], 'Amy', 'Bob')\n",
    "\n",
    "df_weight_winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amy    3\n",
       "Bob    1\n",
       "Name: Winner, dtype: int64"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the winner\n",
    "# If there happen to be lots of months of data\n",
    "\n",
    "df_weight_winner['Winner'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Section Summary\n",
    "1. **`filter`** method returns a boolean for each group\n",
    "2. Group by the index with the **`level`** argument in the **`groupby`** method\n",
    "2. Know how to define custom aggregation and filter functions\n",
    "3. Use **`transform`** when you want to return a Series the same length as the original group\n",
    "4. Map a boolean expression to 2 other values with **`np.where`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set\n",
    "We will be working with the city of Houston dataset for the questions in this notebook. Run the following command before attempting the problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Houston Information Tech Svcs    9\n",
       "Planning & Development           7\n",
       "Mayor's Office                   5\n",
       "City Controller's Office         5\n",
       "Convention and Entertainment     1\n",
       "Name: DEPARTMENT, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 40\n",
    "hou = pd.read_csv('data/coh_employee.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "<span  style=\"color:green; font-size:16px\">What are the 5 least common departments?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Convention and Entertainment    1\n",
       "Name: DEPARTMENT, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 40\n",
    "hou = pd.read_csv('data/coh_employee.csv')\n",
    "\n",
    "hou.DEPARTMENT.value_counts().tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "<span  style=\"color:green; font-size:16px\">Filter out departments with less than 50 occurences and save it to **`hou_filter`**. Then test your code by outputing the frequencies of all the remaining departments. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Houston Police Department-HPD     638\n",
       "Houston Fire Department (HFD)     384\n",
       "Public Works & Engineering-PWE    343\n",
       "Health & Human Services           110\n",
       "Houston Airport System (HAS)      106\n",
       "Parks & Recreation                 74\n",
       "Name: DEPARTMENT, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def min_count(df, threshold):\n",
    "    return len(df['DEPARTMENT']) >= threshold\n",
    "\n",
    "hou_filter = hou.groupby(['DEPARTMENT']).filter(min_count, threshold=50)\n",
    "hou_filter.DEPARTMENT.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "<span  style=\"color:green; font-size:16px\">Filter out departments from the original **`hou`** DataFrame with average salaries less than $70,000 and save it to **`hou_filter_salary`**. Then test your code by outputing the average salaries for the remaining departments.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BASE_SALARY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Admn. &amp; Regulatory Affairs</th>\n",
       "      <td>50890.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City Controller's Office</th>\n",
       "      <td>55711.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City Council</th>\n",
       "      <td>59089.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Convention and Entertainment</th>\n",
       "      <td>38397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dept of Neighborhoods (DON)</th>\n",
       "      <td>47092.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fleet Management Department</th>\n",
       "      <td>43994.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Services Department</th>\n",
       "      <td>51295.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health &amp; Human Services</th>\n",
       "      <td>51305.933962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Housing and Community Devp.</th>\n",
       "      <td>61387.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Airport System (HAS)</th>\n",
       "      <td>53956.066038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Emergency Center (HEC)</th>\n",
       "      <td>46415.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Fire Department (HFD)</th>\n",
       "      <td>59528.867568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Police Department-HPD</th>\n",
       "      <td>60268.495652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Human Resources Dept.</th>\n",
       "      <td>56311.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Library</th>\n",
       "      <td>43997.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Municipal Courts Department</th>\n",
       "      <td>53745.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks &amp; Recreation</th>\n",
       "      <td>39039.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Planning &amp; Development</th>\n",
       "      <td>54879.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public Works &amp; Engineering-PWE</th>\n",
       "      <td>50207.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solid Waste Management</th>\n",
       "      <td>41591.930233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 BASE_SALARY\n",
       "DEPARTMENT                                  \n",
       "Admn. & Regulatory Affairs      50890.551724\n",
       "City Controller's Office        55711.600000\n",
       "City Council                    59089.222222\n",
       "Convention and Entertainment    38397.000000\n",
       "Dept of Neighborhoods (DON)     47092.882353\n",
       "Fleet Management Department     43994.305556\n",
       "General Services Department     51295.818182\n",
       "Health & Human Services         51305.933962\n",
       "Housing and Community Devp.     61387.700000\n",
       "Houston Airport System (HAS)    53956.066038\n",
       "Houston Emergency Center (HEC)  46415.739130\n",
       "Houston Fire Department (HFD)   59528.867568\n",
       "Houston Police Department-HPD   60268.495652\n",
       "Human Resources Dept.           56311.833333\n",
       "Library                         43997.500000\n",
       "Municipal Courts Department     53745.384615\n",
       "Parks & Recreation              39039.272727\n",
       "Planning & Development          54879.571429\n",
       "Public Works & Engineering-PWE  50207.806452\n",
       "Solid Waste Management          41591.930233"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hou_filter_salary = hou.groupby(['DEPARTMENT']).filter(lambda df: df.BASE_SALARY.mean() < 70000)\n",
    "\n",
    "hou_filter_salary.groupby(['DEPARTMENT'])['DEPARTMENT','BASE_SALARY'].agg(np.mean) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "<span  style=\"color:green; font-size:16px\">Filter for thoe departments from the original **`hou`** DataFrame with average salaries of at least 50,000 or having at least 5 unique position titles. Then create a way to check you got the right answer</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1696, 31)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def many_and_high(df, threshold, positions):\n",
    "    return (df.BASE_SALARY.mean() > threshold) or (df.POSITION_TITLE.nunique() >= positions)\n",
    "\n",
    "hou_filter2 = hou.groupby(['DEPARTMENT']).filter(many_and_high, threshold=65000, positions = 25)\n",
    "\n",
    "hou_filter2.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Advanced\n",
    "<span  style=\"color:green; font-size:16px\">Find a way to do problem 4 without using the **`filter`** method. Make clever use of aggregate groupby and boolean logic</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do aggregations for each boolean piece separately\n",
    "salary_grp = hou.groupby('DEPARTMENT')['BASE_SALARY'].mean()\n",
    "uniq_grp = hou.groupby('DEPARTMENT')['POSITION_TITLE'].nunique()\n",
    "\n",
    "salary_grp.head()\n",
    "\n",
    "# create boolean criteria\n",
    "\n",
    "deps = (salary_grp > 65000) | (uniq_grp >= 25)\n",
    "\n",
    "deps\n",
    "\n",
    "# filter Series with itself and grab index values\n",
    "deps_true = deps[deps].index.values\n",
    "\n",
    "deps_true\n",
    "\n",
    "hou_more_check = hou[hou.DEPARTMENT.isin(deps_true)]\n",
    "\n",
    "# can check equality of dataframes with equals method\n",
    "hou_more_check.equals(hou_filter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Advanced\n",
    "<span  style=\"color:green; font-size:16px\">Group by department, gender and race and get the mean, min and max base salary for each group. Also get the number of unique position titles and the most frequent position title for each group. Rename each aggregation to something that makes sense. Then remove the top level of the column index. Hint: This [stackoverflow answer](http://stackoverflow.com/questions/15222754/group-by-pandas-dataframe-and-select-most-common-string-factor) will be useful </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>salary_mean</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>unique_positions</th>\n",
       "      <th>most_frequent_position</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>RACE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Admn. &amp; Regulatory Affairs</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Female</th>\n",
       "      <th>Asian/Pacific Islander</th>\n",
       "      <td>72293.666667</td>\n",
       "      <td>37710.0</td>\n",
       "      <td>130416.0</td>\n",
       "      <td>3</td>\n",
       "      <td>ADMINISTRATIVE ASSOCIATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African American</th>\n",
       "      <td>49727.500000</td>\n",
       "      <td>33550.0</td>\n",
       "      <td>72741.0</td>\n",
       "      <td>8</td>\n",
       "      <td>CUSTOMER SERVICE REPRESENTATIVE I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <td>36616.400000</td>\n",
       "      <td>28205.0</td>\n",
       "      <td>47341.0</td>\n",
       "      <td>4</td>\n",
       "      <td>ANIMAL CARE TECHNICIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>47664.666667</td>\n",
       "      <td>33280.0</td>\n",
       "      <td>62129.0</td>\n",
       "      <td>3</td>\n",
       "      <td>ADMINISTRATIVE SPECIALIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Male</th>\n",
       "      <th>Black or African American</th>\n",
       "      <td>29827.500000</td>\n",
       "      <td>29557.0</td>\n",
       "      <td>30098.0</td>\n",
       "      <td>2</td>\n",
       "      <td>REGULATORY INVESTIGATOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <td>35318.000000</td>\n",
       "      <td>35318.0</td>\n",
       "      <td>35318.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CUSTOMER SERVICE REPRESENTATIVE I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>122096.000000</td>\n",
       "      <td>103776.0</td>\n",
       "      <td>140416.0</td>\n",
       "      <td>2</td>\n",
       "      <td>DEPUTY ASSISTANT DIRECTOR (EXECUTIVE LEV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">City Controller's Office</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Female</th>\n",
       "      <th>Asian/Pacific Islander</th>\n",
       "      <td>59077.000000</td>\n",
       "      <td>59077.0</td>\n",
       "      <td>59077.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ASSISTANT CITY CONTROLLER III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African American</th>\n",
       "      <td>56295.000000</td>\n",
       "      <td>55536.0</td>\n",
       "      <td>57054.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ADMINISTRATIVE ASSISTANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <td>64251.000000</td>\n",
       "      <td>64251.0</td>\n",
       "      <td>64251.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ADMINISTRATIVE ASSISTANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <th>Black or African American</th>\n",
       "      <td>42640.000000</td>\n",
       "      <td>42640.0</td>\n",
       "      <td>42640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FINANCIAL ANALYST I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City Council</th>\n",
       "      <th>Female</th>\n",
       "      <th>Black or African American</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>SENIOR COUNCIL AIDE (EXECUTIVE LEVEL)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               salary_mean  \\\n",
       "DEPARTMENT                 GENDER RACE                                       \n",
       "Admn. & Regulatory Affairs Female Asian/Pacific Islander      72293.666667   \n",
       "                                  Black or African American   49727.500000   \n",
       "                                  Hispanic/Latino             36616.400000   \n",
       "                                  White                       47664.666667   \n",
       "                           Male   Black or African American   29827.500000   \n",
       "                                  Hispanic/Latino             35318.000000   \n",
       "                                  White                      122096.000000   \n",
       "City Controller's Office   Female Asian/Pacific Islander      59077.000000   \n",
       "                                  Black or African American   56295.000000   \n",
       "                                  Hispanic/Latino             64251.000000   \n",
       "                           Male   Black or African American   42640.000000   \n",
       "City Council               Female Black or African American  100000.000000   \n",
       "\n",
       "                                                             salary_min  \\\n",
       "DEPARTMENT                 GENDER RACE                                    \n",
       "Admn. & Regulatory Affairs Female Asian/Pacific Islander        37710.0   \n",
       "                                  Black or African American     33550.0   \n",
       "                                  Hispanic/Latino               28205.0   \n",
       "                                  White                         33280.0   \n",
       "                           Male   Black or African American     29557.0   \n",
       "                                  Hispanic/Latino               35318.0   \n",
       "                                  White                        103776.0   \n",
       "City Controller's Office   Female Asian/Pacific Islander        59077.0   \n",
       "                                  Black or African American     55536.0   \n",
       "                                  Hispanic/Latino               64251.0   \n",
       "                           Male   Black or African American     42640.0   \n",
       "City Council               Female Black or African American    100000.0   \n",
       "\n",
       "                                                             salary_max  \\\n",
       "DEPARTMENT                 GENDER RACE                                    \n",
       "Admn. & Regulatory Affairs Female Asian/Pacific Islander       130416.0   \n",
       "                                  Black or African American     72741.0   \n",
       "                                  Hispanic/Latino               47341.0   \n",
       "                                  White                         62129.0   \n",
       "                           Male   Black or African American     30098.0   \n",
       "                                  Hispanic/Latino               35318.0   \n",
       "                                  White                        140416.0   \n",
       "City Controller's Office   Female Asian/Pacific Islander        59077.0   \n",
       "                                  Black or African American     57054.0   \n",
       "                                  Hispanic/Latino               64251.0   \n",
       "                           Male   Black or African American     42640.0   \n",
       "City Council               Female Black or African American    100000.0   \n",
       "\n",
       "                                                             unique_positions  \\\n",
       "DEPARTMENT                 GENDER RACE                                          \n",
       "Admn. & Regulatory Affairs Female Asian/Pacific Islander                    3   \n",
       "                                  Black or African American                 8   \n",
       "                                  Hispanic/Latino                           4   \n",
       "                                  White                                     3   \n",
       "                           Male   Black or African American                 2   \n",
       "                                  Hispanic/Latino                           1   \n",
       "                                  White                                     2   \n",
       "City Controller's Office   Female Asian/Pacific Islander                    1   \n",
       "                                  Black or African American                 1   \n",
       "                                  Hispanic/Latino                           1   \n",
       "                           Male   Black or African American                 1   \n",
       "City Council               Female Black or African American                 1   \n",
       "\n",
       "                                                                               most_frequent_position  \n",
       "DEPARTMENT                 GENDER RACE                                                                 \n",
       "Admn. & Regulatory Affairs Female Asian/Pacific Islander                     ADMINISTRATIVE ASSOCIATE  \n",
       "                                  Black or African American         CUSTOMER SERVICE REPRESENTATIVE I  \n",
       "                                  Hispanic/Latino                              ANIMAL CARE TECHNICIAN  \n",
       "                                  White                                     ADMINISTRATIVE SPECIALIST  \n",
       "                           Male   Black or African American                   REGULATORY INVESTIGATOR  \n",
       "                                  Hispanic/Latino                   CUSTOMER SERVICE REPRESENTATIVE I  \n",
       "                                  White                      DEPUTY ASSISTANT DIRECTOR (EXECUTIVE LEV  \n",
       "City Controller's Office   Female Asian/Pacific Islander                ASSISTANT CITY CONTROLLER III  \n",
       "                                  Black or African American                  ADMINISTRATIVE ASSISTANT  \n",
       "                                  Hispanic/Latino                            ADMINISTRATIVE ASSISTANT  \n",
       "                           Male   Black or African American                       FINANCIAL ANALYST I  \n",
       "City Council               Female Black or African American     SENIOR COUNCIL AIDE (EXECUTIVE LEVEL)  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = hou.groupby(['DEPARTMENT', 'GENDER','RACE']).agg({'BASE_SALARY':{'salary_mean':'mean',\n",
    "                                                                'salary_min':'min',\n",
    "                                                                'salary_max':'max'},\n",
    "                                                 'POSITION_TITLE':{'unique_positions':'nunique',\n",
    "                                                                  'most_frequent_position':lambda x: x.value_counts().index[0]}})\n",
    "\n",
    "df.columns = df.columns.droplevel(0)\n",
    "\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7\n",
    "<span  style=\"color:green; font-size:16px\"> Create a column **`is_max`** that is equal to 1 if the base salary is currently the max base salary (out of all previous rows) for that department and 0 otherwise. Save the returned DataFrame to **`hou_1`**. Output the first 20 rows. See sample data below.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BASE_SALARY</th>\n",
       "      <th>is_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Municipal Courts Department</td>\n",
       "      <td>121862.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Library</td>\n",
       "      <td>26125.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>63166.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Services Department</td>\n",
       "      <td>56347.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>71680.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>42390.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>107962.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>44616.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>52644.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>180416.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>30347.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>55269.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>77076.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>81239.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>General Services Department</td>\n",
       "      <td>40581.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DEPARTMENT  BASE_SALARY  is_max\n",
       "0      Municipal Courts Department     121862.0     1.0\n",
       "1                          Library      26125.0     1.0\n",
       "2    Houston Police Department-HPD      45279.0     1.0\n",
       "3    Houston Fire Department (HFD)      63166.0     1.0\n",
       "4      General Services Department      56347.0     1.0\n",
       "5    Houston Police Department-HPD      66614.0     1.0\n",
       "6   Public Works & Engineering-PWE      71680.0     1.0\n",
       "7     Houston Airport System (HAS)      42390.0     1.0\n",
       "8   Public Works & Engineering-PWE     107962.0     1.0\n",
       "9     Houston Airport System (HAS)      44616.0     1.0\n",
       "10   Houston Fire Department (HFD)      52644.0     0.0\n",
       "11         Health & Human Services     180416.0     1.0\n",
       "12  Public Works & Engineering-PWE      30347.0     0.0\n",
       "13         Health & Human Services      55269.0     0.0\n",
       "14   Houston Police Department-HPD      77076.0     1.0\n",
       "15   Houston Police Department-HPD          NaN     0.0\n",
       "16   Houston Police Department-HPD          NaN     0.0\n",
       "17   Houston Police Department-HPD      81239.0     1.0\n",
       "18     General Services Department      40581.0     0.0\n",
       "19   Houston Police Department-HPD      66614.0     0.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a dataframe that looks like this\n",
    "''' \n",
    "DEPARTMENT    BASE_SALARY  is_max  \n",
    "Library           160         1\n",
    "Police            150         1\n",
    "Library           170         1\n",
    "Police             95         0\n",
    "Police            140         0\n",
    "Library            80         0\n",
    "Police            189         1\n",
    "'''\n",
    "\n",
    "\n",
    "hou_1 = hou[['DEPARTMENT', 'BASE_SALARY']].copy()\n",
    "hou_1['is_max'] = hou_1.groupby('DEPARTMENT')['BASE_SALARY'].transform(lambda x: x == x.cummax())\n",
    "hou_1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for simplicity start with this dataframe\n",
    "hou_1 = hou[['DEPARTMENT', 'BASE_SALARY']].copy() # copy so that we don't overwrite the original data\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: Advanced\n",
    "<span  style=\"color:green; font-size:16px\"> Programatically Find the 10th occurence of 0 for **`is_max`** and return a DataFrame that ends after the tenth occurence.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BASE_SALARY</th>\n",
       "      <th>is_max</th>\n",
       "      <th>occur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Municipal Courts Department</td>\n",
       "      <td>121862.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Library</td>\n",
       "      <td>26125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>63166.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Services Department</td>\n",
       "      <td>56347.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>71680.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>42390.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>107962.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>44616.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>52644.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>180416.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>30347.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>55269.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>77076.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>81239.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>General Services Department</td>\n",
       "      <td>40581.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>61506.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>57815.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>43264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>55437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DEPARTMENT  BASE_SALARY  is_max  occur\n",
       "0      Municipal Courts Department     121862.0     1.0      0\n",
       "1                          Library      26125.0     1.0      1\n",
       "2    Houston Police Department-HPD      45279.0     1.0      2\n",
       "3    Houston Fire Department (HFD)      63166.0     1.0      3\n",
       "4      General Services Department      56347.0     1.0      4\n",
       "5    Houston Police Department-HPD      66614.0     1.0      5\n",
       "6   Public Works & Engineering-PWE      71680.0     1.0      6\n",
       "7     Houston Airport System (HAS)      42390.0     1.0      7\n",
       "8   Public Works & Engineering-PWE     107962.0     1.0      8\n",
       "9     Houston Airport System (HAS)      44616.0     1.0      9\n",
       "10   Houston Fire Department (HFD)      52644.0     0.0      0\n",
       "11         Health & Human Services     180416.0     1.0     10\n",
       "12  Public Works & Engineering-PWE      30347.0     0.0      1\n",
       "13         Health & Human Services      55269.0     0.0      2\n",
       "14   Houston Police Department-HPD      77076.0     1.0     11\n",
       "15   Houston Police Department-HPD          NaN     0.0      3\n",
       "16   Houston Police Department-HPD          NaN     0.0      4\n",
       "17   Houston Police Department-HPD      81239.0     1.0     12\n",
       "18     General Services Department      40581.0     0.0      5\n",
       "19   Houston Police Department-HPD      66614.0     0.0      6\n",
       "20  Public Works & Engineering-PWE      61506.0     0.0      7\n",
       "21   Houston Fire Department (HFD)      57815.0     0.0      8\n",
       "22  Public Works & Engineering-PWE      43264.0     0.0      9\n",
       "23   Houston Fire Department (HFD)      55437.0     0.0     10"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hou_1 = hou[['DEPARTMENT', 'BASE_SALARY']].copy()\n",
    "hou_1['is_max'] = hou_1.groupby('DEPARTMENT')['BASE_SALARY'].transform(lambda x: x == x.cummax())\n",
    "\n",
    "hou_1['occur'] = hou_1.groupby('is_max').cumcount()\n",
    "hou_1.head(20)\n",
    "idx_10 = hou_1.index[(hou_1.occur == 10) & (hou_1.is_max == 0)][0]\n",
    "idx_10\n",
    "hou_1.loc[:idx_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9\n",
    "<span  style=\"color:green; font-size:16px\"> Write a function that accepts a single argument that will filter **`hou_1`** for a specific department where **`is_max`** is 1. Test your function with departments like 'Library' and 'Public Works & Engineering-PWE'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BASE_SALARY</th>\n",
       "      <th>is_max</th>\n",
       "      <th>occur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>71680.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>107962.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>110881.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>141948.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>146141.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>178331.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          DEPARTMENT  BASE_SALARY  is_max  occur\n",
       "6     Public Works & Engineering-PWE      71680.0     1.0      6\n",
       "8     Public Works & Engineering-PWE     107962.0     1.0      8\n",
       "186   Public Works & Engineering-PWE     110881.0     1.0     39\n",
       "297   Public Works & Engineering-PWE     141948.0     1.0     50\n",
       "1067  Public Works & Engineering-PWE     146141.0     1.0     77\n",
       "1232  Public Works & Engineering-PWE     178331.0     1.0     80"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_dep(dep):\n",
    "    criteria = (hou_1.DEPARTMENT == dep) & (hou_1.is_max == 1)\n",
    "    return hou_1[criteria]\n",
    "\n",
    "filter_dep('Library')\n",
    "\n",
    "filter_dep('Public Works & Engineering-PWE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10\n",
    "<span  style=\"color:green; font-size:16px\">A good skill to have is to ask a difficult question for yourself and then answer it. Ask yourself a question that involes grouping and answer it.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
