{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study - Counting pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to count all the functions, methods and attributes that pandas has to offer?\n",
    "There are probably multiple intelligent ways to do this but for this exercise we will start off by assuming the [API reference](http://pandas.pydata.org/pandas-docs/stable/api.html) in the pandas docs contain all the functionality of pandas. Full URL: http://pandas.pydata.org/pandas-docs/stable/api.html\n",
    "\n",
    "Wow, thats an absurd amount of functionality for one library. Manually counting this might take some time. Lets use pandas to help us out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding pages with html tables\n",
    "\n",
    "Many times it will not be obvious that a web page consists of html tables. For example, the Pandas api reference web page does not appear to have what you would normally define as a 'table'. However, all modern browsers have functionality to nicely display the contents of the current html page. In chrome you can right click **inspect** or **view page source**. If you click inspec, then the html for that object will be directly navigated to.\n",
    "\n",
    "Once inspecting the html you can use search functions to find html tables which are always written with **`<table>`** elements.\n",
    "\n",
    "Go ahead and inspect the api page and see if the underlying elements are indeed html tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `read_html` to scrape tables\n",
    "\n",
    "Pandas has a handy-dandy function **`read_html`** which reads all the html tables off of the given url. It returns a list of pandas dataframe objects - one for each table found. Let's use this now to grab every single table on that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grab all html tables from api reference page\n",
    "api_tables = pd.read_html('http://pandas.pydata.org/pandas-docs/stable/api.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many tables are there\n",
    "len(api_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>read_pickle(path)</td>\n",
       "      <td>Load pickled pandas object (or any other pickl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0                                                  1\n",
       "0  read_pickle(path)  Load pickled pandas object (or any other pickl..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets look at a few tables\n",
    "api_tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Series.from_csv(path[, sep, parse_dates, ...])</td>\n",
       "      <td>Read CSV file (DISCOURAGED, please use pandas....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Series.to_pickle(path)</td>\n",
       "      <td>Pickle (serialize) object to input file path.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series.to_csv([path, index, sep, na_rep, ...])</td>\n",
       "      <td>Write Series to a comma-separated values (csv)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Series.to_dict()</td>\n",
       "      <td>Convert Series to {label -&gt; value} dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series.to_frame([name])</td>\n",
       "      <td>Convert Series to DataFrame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Series.to_xarray()</td>\n",
       "      <td>Return an xarray object from the pandas object.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Series.to_hdf(path_or_buf, key, \\*\\*kwargs)</td>\n",
       "      <td>Write the contained data to an HDF5 file using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Series.to_sql(name, con[, flavor, schema, ...])</td>\n",
       "      <td>Write records stored in a DataFrame to a SQL d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Series.to_msgpack([path_or_buf, encoding])</td>\n",
       "      <td>msgpack (serialize) object to input file path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Series.to_json([path_or_buf, orient, ...])</td>\n",
       "      <td>Convert the object to a JSON string.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Series.to_sparse([kind, fill_value])</td>\n",
       "      <td>Convert Series to SparseSeries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Series.to_dense()</td>\n",
       "      <td>Return dense representation of NDFrame (as opp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Series.to_string([buf, na_rep, ...])</td>\n",
       "      <td>Render a string representation of the Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Series.to_clipboard([excel, sep])</td>\n",
       "      <td>Attempt to write text representation of object...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0  \\\n",
       "0    Series.from_csv(path[, sep, parse_dates, ...])   \n",
       "1                            Series.to_pickle(path)   \n",
       "2    Series.to_csv([path, index, sep, na_rep, ...])   \n",
       "3                                  Series.to_dict()   \n",
       "4                           Series.to_frame([name])   \n",
       "5                                Series.to_xarray()   \n",
       "6       Series.to_hdf(path_or_buf, key, \\*\\*kwargs)   \n",
       "7   Series.to_sql(name, con[, flavor, schema, ...])   \n",
       "8        Series.to_msgpack([path_or_buf, encoding])   \n",
       "9        Series.to_json([path_or_buf, orient, ...])   \n",
       "10             Series.to_sparse([kind, fill_value])   \n",
       "11                                Series.to_dense()   \n",
       "12             Series.to_string([buf, na_rep, ...])   \n",
       "13                Series.to_clipboard([excel, sep])   \n",
       "\n",
       "                                                    1  \n",
       "0   Read CSV file (DISCOURAGED, please use pandas....  \n",
       "1       Pickle (serialize) object to input file path.  \n",
       "2   Write Series to a comma-separated values (csv)...  \n",
       "3             Convert Series to {label -> value} dict  \n",
       "4                         Convert Series to DataFrame  \n",
       "5     Return an xarray object from the pandas object.  \n",
       "6   Write the contained data to an HDF5 file using...  \n",
       "7   Write records stored in a DataFrame to a SQL d...  \n",
       "8       msgpack (serialize) object to input file path  \n",
       "9                Convert the object to a JSON string.  \n",
       "10                     Convert Series to SparseSeries  \n",
       "11  Return dense representation of NDFrame (as opp...  \n",
       "12       Render a string representation of the Series  \n",
       "13  Attempt to write text representation of object...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at another table\n",
    "api_tables[44]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like they are all two column tables with the attribute in the first column and the description in the right column. Every thing looks good. Lets try counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 943 things pandas can do!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for table in api_tables:\n",
    "    count += table.shape[0]\n",
    "print(\"There are {} things pandas can do!\".format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much functionality does the pandas Series have?\n",
    "As seen above, the pandas object is followed up by its method/attribute in object-oriented notation. If we want to count just the Series functionality we need to search each table's first column for the word `Series`. pandas again provides us with some nicely equipped with plenty of [string processing methods](http://pandas.pydata.org/pandas-docs/stable/text.html).\n",
    "\n",
    "To use these string processing methods, define a pandas Series and use .str. and press tab to see all the available methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Series.from_csv(path[, sep, parse_dates, ...])\n",
       "1                            Series.to_pickle(path)\n",
       "2    Series.to_csv([path, index, sep, na_rep, ...])\n",
       "3                                  Series.to_dict()\n",
       "4                           Series.to_frame([name])\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets use the first column from the above table\n",
    "s = api_tables[44][0]\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2     True\n",
       "3     True\n",
       "4     True\n",
       "5     True\n",
       "6     True\n",
       "7     True\n",
       "8     True\n",
       "9     True\n",
       "10    True\n",
       "11    True\n",
       "12    True\n",
       "13    True\n",
       "Name: 0, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the str.contains method to see if each item does in fact contain the word 'Series' in it\n",
    "s.str.contains('Series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 283 things pandas Series can do!\n"
     ]
    }
   ],
   "source": [
    "# OK lets count the appearance of \n",
    "count_series = 0\n",
    "for table in api_tables:\n",
    "    count_series += table[0].str.contains('Series').sum()\n",
    "print(\"There are {} things pandas Series can do!\".format(count_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "<span  style=\"color:green; font-size:16px\"> Writing a new for loop every time we want to count a new word in our dataset is cumbersome. Can you write a function that accepts the parameter **word** and returns the count of this word if it appears as in the pandas API as a functions/methods/attributes. Count a few words with it like DataFrame or MultiIndex</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def count_functionality(word):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "<span  style=\"color:green; font-size:16px\">Define a new function by modifying the above function slightly to have it return a list of all the methods</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "<span  style=\"color:green; font-size:16px\">Explore several of the Series `.str` methods that you should now have captured in a list on one of the API reference tables to get </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "<span  style=\"color:green; font-size:16px\">Lets get some 'live' data.</span>\n",
    "1. Naviate to [real clear politics Trump vs Clinton](http://www.realclearpolitics.com/epolls/2016/president/us/general_election_trump_vs_clinton-5491.html) \n",
    "1. use pandas **`read_html`** to read in that full table at the bottom of the page and display it here in the notebook\n",
    "1. use the header parameter to find the correct header instead of the default numbers\n",
    "1. Inspect the info to make sure the clinton and trump data types are float64\n",
    "1. add a column that calculates the difference of trump vs clinton\n",
    "1. sort the dataframe by this newly created column\n",
    "1. What conclusions (if any) can you make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
